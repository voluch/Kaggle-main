{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.cross_validation import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dataset and separate features from labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\numpy\\lib\\function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "path = r\"C:\\Users\\User\\Kaggle\\Kaggle-main\\Titanic\\titanic\" + \"\\\\\"\n",
    "train = pd.read_csv(path + \"train.csv\")\n",
    "test = pd.read_csv(path + \"test.csv\")\n",
    "\n",
    "train.describe()\n",
    "test.describe()\n",
    "print(train.isnull().sum())\n",
    "print(test.isnull().sum())\n",
    "\n",
    "train.info()\n",
    "test.info()\n",
    "  \n",
    "X = train.iloc[:, 0]\n",
    "X = pd.concat([X, train.iloc[:, 2:]], axis = 1)\n",
    "y_train = train.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing datasets function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'remove_nan_from_age' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e4985e0b3bf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-e4985e0b3bf7>\u001b[0m in \u001b[0;36mpreprocessing\u001b[0;34m(train)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mremove_nan_from_age\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'remove_nan_from_age' is not defined"
     ]
    }
   ],
   "source": [
    "def preprocessing(train):\n",
    "    \"\"\"\n",
    "    Clearing 'Ticket' column\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for i in range(0,train['Ticket'].size):\n",
    "        if [int(j) for j in train.loc[i,'Ticket'].split() if j.isdigit()] == []:\n",
    "            res.append(None)\n",
    "        else:\n",
    "            res.append([int(j) for j in train.loc[i,'Ticket'].split() if j.isdigit()][0])\n",
    "    train[\"clear_ticket\"] = res\n",
    "    \n",
    "    \"\"\"\n",
    "    Clearing passenger's Status\n",
    "    \"\"\"\n",
    "    status = []\n",
    "    for i in range(0,train['Ticket'].size):\n",
    "        status.append((train.loc[i,'Name'].split(\", \"))[1].split(\".\")[0])\n",
    "    train[\"clear_status\"] = status\n",
    "\n",
    "\n",
    "    train = train.fillna(value = {'clear_ticket': 0, 'Embarked': 0})\n",
    "\n",
    "\n",
    "    train = remove_nan_from_age(train, 3, 4, 5, 6, 7)\n",
    "    train = train.fillna(train.mean())\n",
    "    \n",
    "    \"\"\"\n",
    "    Get dummies from Categorical variables\n",
    "    \"\"\"\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    import pandas as pd\n",
    "\n",
    "    lbe = LabelEncoder()\n",
    "    train['Sex'] = lbe.fit_transform(train['Sex'])\n",
    "    dummies = pd.get_dummies(train.loc[:, ['Embarked', 'clear_status']], prefix = ['Embarked', 'Status'])\n",
    "    train = pd.concat([train, dummies], axis = 1)\n",
    "    train = train[['PassengerId', 'Pclass', 'Sex', 'Age', 'SibSp',\n",
    "       'Parch', 'Fare', 'clear_ticket', 'Embarked_C', 'Embarked_Q', 'Status_Col', 'Status_Dr',\n",
    "       'Status_Master', 'Status_Miss', 'Status_Mr', 'Status_Mrs',\n",
    "       'Status_Ms', 'Status_Rev']]\n",
    "    return train\n",
    "    \n",
    "    \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Decision tree or Random Forest algorithm to replace NaNs in Age column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_nan_from_age(frame_orig, name_col_numb, sex_col_numb, Age_col_numb, sibsp_col_numb, parch_col_numb):\n",
    "    frame = frame_orig\n",
    "    cluster = []\n",
    "    for i in range(0,frame['Ticket'].size):\n",
    "        if frame.iloc[i, sibsp_col_numb] == 0 and frame.iloc[i, parch_col_numb] == 0:\n",
    "            cluster.append(0)\n",
    "        elif frame.iloc[i, sex_col_numb] == 'female' and '(' in frame.iloc[i, name_col_numb] and frame.iloc[i, sibsp_col_numb] > 0 and frame.iloc[i, parch_col_numb] > 0:\n",
    "            cluster.append(1)\n",
    "        elif frame.iloc[i, sex_col_numb] == 'female' and '(' not in frame.iloc[i, name_col_numb] and frame.iloc[i, parch_col_numb] > 1:\n",
    "            cluster.append(2)\n",
    "        elif frame.iloc[i, sex_col_numb] == 'female' and '(' not in frame.iloc[i, name_col_numb] and frame.iloc[i, parch_col_numb] == 1:\n",
    "            cluster.append(3)\n",
    "        elif frame.iloc[i, sex_col_numb] == 'female' and '(' not in frame.iloc[i, name_col_numb] and frame.iloc[i, parch_col_numb] == 0 and frame.iloc[i, sibsp_col_numb] > 0:\n",
    "            cluster.append(4)\n",
    "        elif frame.iloc[i, sex_col_numb] == 'male' and frame.iloc[i, sibsp_col_numb] == 0 and frame.iloc[i, parch_col_numb] == 1:\n",
    "            cluster.append(5)\n",
    "        elif frame.iloc[i, sex_col_numb] == 'male' and frame.iloc[i, sibsp_col_numb] == 0 and frame.iloc[i, parch_col_numb] > 1:\n",
    "            cluster.append(6)\n",
    "        elif frame.iloc[i, sex_col_numb] == 'male' and frame.iloc[i, sibsp_col_numb] > 0 and frame.iloc[i, parch_col_numb] == 0:\n",
    "            cluster.append(7)\n",
    "        elif frame.iloc[i, sex_col_numb] == 'male' and frame.iloc[i, sibsp_col_numb] == 1 and frame.iloc[i, parch_col_numb] > 0:\n",
    "            cluster.append(8)\n",
    "        elif frame.iloc[i, sex_col_numb] == 'male' and frame.iloc[i, sibsp_col_numb] > 1 and frame.iloc[i, parch_col_numb] > 0:\n",
    "            cluster.append(9)\n",
    "        else:\n",
    "            cluster.append(10)\n",
    "    frame['cluster'] = cluster\n",
    "    cluster_median = frame.groupby('cluster')['Age'].median().reset_index() \n",
    "    for i in range(0,frame['Ticket'].size):\n",
    "        if not frame.iloc[i,Age_col_numb] > -1:\n",
    "            frame.iloc[i,Age_col_numb] = cluster_median.iloc[frame.iloc[i,frame.shape[1] - 1],1]\n",
    "    return frame\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataframe on test and train datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = preprocessing(X)\n",
    "X_test = preprocessing(test)\n",
    "\n",
    "print(X_train.isnull().sum())\n",
    "print(X_test.isnull().sum())\n",
    "X_train_model, X_test_model, y_train_model, y_test_model = train_test_split(X_train, y_train, test_size = 0.2, random_state = 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "sc_X = StandardScaler()X_train = sc_X.fit_transform(X_train)X_test = sc_X.transform(X_test)sc_y = StandardScaler()y_train = sc_y.fit_transform(y_train)\n",
    "res = [int(i) for i in test_string.split() if i.isdigit()]\n",
    "imputer = Imputer(missing_values = \"NaN\", strategy = \"mean\", axis = 0)\n",
    "imputer = imputer.fit(train.iloc[:, [5, 9]])\n",
    "train.iloc[:, [5, 9]] = imputer.transform(train.iloc[:, [5, 9]])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train_model, y_train_model)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test_model, classifier.predict(X_test_model))\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
